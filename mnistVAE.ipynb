{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "mnistVAE.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqhaQvvV8kwG",
        "colab_type": "text"
      },
      "source": [
        "# Variational autoencoders \n",
        "Acknowledgment: Some pieces of code are taken from this tutorial \n",
        "https://tiao.io/post/tutorial-on-variational-autoencoders-with-a-concise-keras-implementation/\n",
        "\n",
        "In this tutorial, we will be using Keras to implement a variational autoencoder which will have a number in a given style as an input and the same number in different other styles as an output.\n",
        "\n",
        "##### Keras\n",
        "It is an open-source neural-network library written in Python. It is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, R, Theano, or PlaidML.\n",
        "Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular and extensible.\n",
        "\n",
        "##### libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esUKWP3u8kwJ",
        "colab_type": "code",
        "outputId": "81f1d5bb-6708-4f60-cc62-8dbf97d618e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "from keras import backend as K\n",
        "import keras as Keras \n",
        "\n",
        "from keras.layers import (Input, InputLayer, Dense, Lambda, Layer, Add, Multiply)\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "from IPython.display import SVG\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zMoWfKY8kwR",
        "colab_type": "text"
      },
      "source": [
        "# **Notebook configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-XA9JU98kwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision=2,\n",
        "                    edgeitems=3,\n",
        "                    linewidth=80,\n",
        "                    suppress=True)\n",
        "#These options determine the way floating point numbers, arrays and other NumPy objects are displayed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV6EIY0j8kwb",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset (MNIST)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwU1GYq8kwd",
        "colab_type": "code",
        "outputId": "18c46c94-5856-4dd6-e567-915dcca1c71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Mnist dataset\n",
        "# x are the pictures of the digits and y are the labels of digits \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, axis=-1) / 255.\n",
        "x_test = np.expand_dims(x_test, axis=-1) / 255.\n",
        "#Dimensions \n",
        "img_rows, img_cols, img_chns = x_train.shape[1:]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUc6XZLDU_Yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, axis=-1) / 255.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14pvNseK8yTG",
        "colab_type": "code",
        "outputId": "18d83896-285b-4d32-ba56-0ec67fef283f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape[1:]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_TAYAeFDEwE",
        "colab_type": "text"
      },
      "source": [
        "As seen from the shape of the x_train data, it has 28 rows and 28 columns (28x28 pixels), with each value being kept as an array. **Hence, the data is 784 dimensional**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr0F-90K8kwn",
        "colab_type": "text"
      },
      "source": [
        "# **Constant definitions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MizQLsTa8kws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y in a one-hot vector which gives the class of the digit (from 0 to 9).So it has a dimension of 10.\n",
        "Y_dim=10\n",
        "Y_embed_dim = 128\n",
        "Z_dim=128\n",
        "#the dimension of the input of the VAE\n",
        "original_dim = img_rows * img_cols+Y_dim\n",
        "#the dimension of the intermediate layer \n",
        "intermediate_dim = 256\n",
        "#the dimension of the latent variable (Z+Y)\n",
        "latent_dim = Y_dim+Z_dim\n",
        "#training constants\n",
        "batch_size = 100\n",
        "epochs = 50\n",
        "epsilon_std = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQUjfUmW8kw3",
        "colab_type": "text"
      },
      "source": [
        "# **Negative log likelihood (Bernoulli)**\n",
        "## This first term is the **reconstruction loss** (the negative log likelihood of the *i*-th data point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAnH8_bE8kw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(y_true, y_pred):\n",
        "    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n",
        "\n",
        "    # keras.losses.binary_crossentropy gives the mean\n",
        "    # over the last axis. we require the sum\n",
        "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm30QC3E8kxC",
        "colab_type": "text"
      },
      "source": [
        "# **KL-Divergence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTtVJPDW8kxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KLDivergenceLayer(Layer):\n",
        "\n",
        "    \"\"\" Identity transform layer that adds KL divergence\n",
        "    to the final model loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        mu, log_var = inputs\n",
        "\n",
        "        kl_batch = - .5 * K.sum(1 + log_var -\n",
        "                                K.square(mu) -\n",
        "                                K.exp(log_var), axis=-1)\n",
        "\n",
        "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
        "\n",
        "        return inputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYny2IjrGFGL",
        "colab_type": "text"
      },
      "source": [
        "# **The Re-parametrization trick**\n",
        "\n",
        "## The re-parametrization trick allows us to include the randomness of a normally distributed random variable *Z* into epsilon, where ϵ ~ *N(0,1)*:\n",
        "\n",
        "\n",
        "```\n",
        "Z= μ + σ.ϵ\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIuJ5owfO9y-",
        "colab_type": "text"
      },
      "source": [
        "The encoder q(z|x) is a neural network that encodes the 784 dimensional data into a latent representaion space Z which is 128 dimensional.\n",
        "\n",
        "The decoder p(x|z) is a neural network takes in the input of representation *z* and outputs 784 bernoulli parameters (one for each pixel in the image). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8w1RatL8kxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoder\n",
        "#Inference network\n",
        "x = Input(shape=(original_dim,),name='x') # Shape = 784+10\n",
        "h = Dense(intermediate_dim, activation='relu',name='hidden_layer_encoder')(x)\n",
        "\n",
        "z_mu = Dense(Z_dim, name='mu')(h)\n",
        "z_log_var = Dense(Z_dim, name='log_var')(h)\n",
        "\n",
        "z_mu, z_log_var = KLDivergenceLayer(name='KLDivergence')([z_mu, z_log_var])\n",
        "z_sigma = Lambda(lambda t: K.exp(.5*t), name='sigma')(z_log_var)\n",
        "\n",
        "# Reparameterization with Merge Layers\n",
        "eps = Input(tensor=K.random_normal(shape=(K.shape(x)[0], \n",
        "                                          Z_dim)), name='epsilon')\n",
        "\n",
        "z_eps = Multiply(name='z_eps')([z_sigma, eps])\n",
        "Z = Add(name='z')([z_mu, z_eps])\n",
        "Y=Input(tensor=tf.slice(x,[0,0],[-1,Y_dim]), name='Y')\n",
        "zy=Keras.layers.Concatenate(name='z_Y')([Z, Y])\n",
        "\n",
        "#Decoder\n",
        "decoder = Sequential([\n",
        "    Dense(intermediate_dim, input_dim=latent_dim, activation='relu', name='hidden_dec'),\n",
        "    Dense(original_dim, activation='sigmoid', name='x_pred')\n",
        "], name='decoder')\n",
        "\n",
        "#Output\n",
        "x_pred = decoder(zy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgOrbcVk8kxT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Specifying the VAE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJk1UyAU8kxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae = Model(inputs=[x, eps ,Y], outputs=x_pred, name='vae')\n",
        "vae.compile(optimizer='rmsprop', loss=nll)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaGUe1Ly8kxd",
        "colab_type": "text"
      },
      "source": [
        "# **Simplified architecture visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV1gw3DN8kxf",
        "colab_type": "code",
        "outputId": "abc0016e-39ba-4925-da5d-e4353844b3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pydotplus\n",
        "import pydot\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import keras\n",
        "keras.utils.vis_utils.pydot = pydot\n",
        "\n",
        "SVG(model_to_dot(vae, show_shapes=True)\n",
        "    .create(prog='dot', format='svg'))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"959pt\" viewBox=\"0.00 0.00 875.50 719.00\" width=\"1167pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 715)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-715 871.5,-715 871.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139965709633688 -->\n<g class=\"node\" id=\"node1\">\n<title>139965709633688</title>\n<polygon fill=\"none\" points=\"227,-664.5 227,-710.5 467,-710.5 467,-664.5 227,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-683.8\">x: InputLayer</text>\n<polyline fill=\"none\" points=\"322,-664.5 322,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"322,-687.5 380,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"380,-664.5 380,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423.5\" y=\"-695.3\">(None, 794)</text>\n<polyline fill=\"none\" points=\"380,-687.5 467,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423.5\" y=\"-672.3\">(None, 794)</text>\n</g>\n<!-- 139965709633408 -->\n<g class=\"node\" id=\"node2\">\n<title>139965709633408</title>\n<polygon fill=\"none\" points=\"181,-581.5 181,-627.5 513,-627.5 513,-581.5 181,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-600.8\">hidden_layer_encoder: Dense</text>\n<polyline fill=\"none\" points=\"368,-581.5 368,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"368,-604.5 426,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"426,-581.5 426,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-612.3\">(None, 794)</text>\n<polyline fill=\"none\" points=\"426,-604.5 513,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-589.3\">(None, 256)</text>\n</g>\n<!-- 139965709633688&#45;&gt;139965709633408 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139965709633688-&gt;139965709633408</title>\n<path d=\"M347,-664.3799C347,-656.1745 347,-646.7679 347,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"350.5001,-637.784 347,-627.784 343.5001,-637.784 350.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709634248 -->\n<g class=\"node\" id=\"node3\">\n<title>139965709634248</title>\n<polygon fill=\"none\" points=\"108.5,-498.5 108.5,-544.5 331.5,-544.5 331.5,-498.5 108.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.5\" y=\"-517.8\">mu: Dense</text>\n<polyline fill=\"none\" points=\"186.5,-498.5 186.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"186.5,-521.5 244.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"244.5,-498.5 244.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-529.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"244.5,-521.5 331.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-506.3\">(None, 128)</text>\n</g>\n<!-- 139965709633408&#45;&gt;139965709634248 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139965709633408-&gt;139965709634248</title>\n<path d=\"M311.6234,-581.3799C296.8848,-571.7475 279.613,-560.4597 264.0625,-550.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"265.913,-547.325 255.6273,-544.784 262.0834,-553.1846 265.913,-547.325\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709634472 -->\n<g class=\"node\" id=\"node4\">\n<title>139965709634472</title>\n<polygon fill=\"none\" points=\"349.5,-498.5 349.5,-544.5 598.5,-544.5 598.5,-498.5 349.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-517.8\">log_var: Dense</text>\n<polyline fill=\"none\" points=\"453.5,-498.5 453.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"482.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"453.5,-521.5 511.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"482.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"511.5,-498.5 511.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-529.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"511.5,-521.5 598.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-506.3\">(None, 128)</text>\n</g>\n<!-- 139965709633408&#45;&gt;139965709634472 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139965709633408-&gt;139965709634472</title>\n<path d=\"M382.3766,-581.3799C397.1152,-571.7475 414.387,-560.4597 429.9375,-550.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"431.9166,-553.1846 438.3727,-544.784 428.087,-547.325 431.9166,-553.1846\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709635144 -->\n<g class=\"node\" id=\"node5\">\n<title>139965709635144</title>\n<polygon fill=\"none\" points=\"117.5,-415.5 117.5,-461.5 576.5,-461.5 576.5,-415.5 117.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-434.8\">KLDivergence: KLDivergenceLayer</text>\n<polyline fill=\"none\" points=\"344.5,-415.5 344.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"344.5,-438.5 402.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"402.5,-415.5 402.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"489.5\" y=\"-446.3\">[(None, 128), (None, 128)]</text>\n<polyline fill=\"none\" points=\"402.5,-438.5 576.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"489.5\" y=\"-423.3\">[(None, 128), (None, 128)]</text>\n</g>\n<!-- 139965709634248&#45;&gt;139965709635144 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139965709634248-&gt;139965709635144</title>\n<path d=\"M255.3766,-498.3799C270.1152,-488.7475 287.387,-477.4597 302.9375,-467.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"304.9166,-470.1846 311.3727,-461.784 301.087,-464.325 304.9166,-470.1846\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709634472&#45;&gt;139965709635144 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139965709634472-&gt;139965709635144</title>\n<path d=\"M438.6234,-498.3799C423.8848,-488.7475 406.613,-477.4597 391.0625,-467.2967\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"392.913,-464.325 382.6273,-461.784 389.0834,-470.1846 392.913,-464.325\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709585656 -->\n<g class=\"node\" id=\"node6\">\n<title>139965709585656</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 250,-378.5 250,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-351.8\">sigma: Lambda</text>\n<polyline fill=\"none\" points=\"105,-332.5 105,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"105,-355.5 163,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"163,-332.5 163,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-363.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"163,-355.5 250,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-340.3\">(None, 128)</text>\n</g>\n<!-- 139965709635144&#45;&gt;139965709585656 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139965709635144-&gt;139965709585656</title>\n<path d=\"M285.4554,-415.4901C257.7865,-405.1454 224.9641,-392.874 196.2364,-382.1334\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"197.2568,-378.7783 186.6643,-378.5547 194.8053,-385.3351 197.2568,-378.7783\" stroke=\"#000000\"/>\n</g>\n<!-- 139965606349512 -->\n<g class=\"node\" id=\"node9\">\n<title>139965606349512</title>\n<polygon fill=\"none\" points=\"327.5,-166.5 327.5,-212.5 614.5,-212.5 614.5,-166.5 327.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-185.8\">z: Add</text>\n<polyline fill=\"none\" points=\"382.5,-166.5 382.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"382.5,-189.5 440.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"440.5,-166.5 440.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"527.5\" y=\"-197.3\">[(None, 128), (None, 128)]</text>\n<polyline fill=\"none\" points=\"440.5,-189.5 614.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"527.5\" y=\"-174.3\">(None, 128)</text>\n</g>\n<!-- 139965709635144&#45;&gt;139965606349512 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139965709635144-&gt;139965606349512</title>\n<path d=\"M470.1568,-415.4404C506.7182,-405.9409 539.9876,-393.6832 551,-379 585.6667,-332.7778 576.9426,-300.6261 551,-249 545.0545,-237.1683 535.5185,-227.0947 525.0688,-218.7849\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"527.0649,-215.908 516.9441,-212.7743 522.9017,-221.5354 527.0649,-215.908\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709585376 -->\n<g class=\"node\" id=\"node8\">\n<title>139965709585376</title>\n<polygon fill=\"none\" points=\"202.5,-249.5 202.5,-295.5 541.5,-295.5 541.5,-249.5 202.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-268.8\">z_eps: Multiply</text>\n<polyline fill=\"none\" points=\"309.5,-249.5 309.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"309.5,-272.5 367.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"367.5,-249.5 367.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454.5\" y=\"-280.3\">[(None, 128), (None, 128)]</text>\n<polyline fill=\"none\" points=\"367.5,-272.5 541.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454.5\" y=\"-257.3\">(None, 128)</text>\n</g>\n<!-- 139965709585656&#45;&gt;139965709585376 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139965709585656-&gt;139965709585376</title>\n<path d=\"M193.4753,-332.4901C224.5278,-322.0554 261.4142,-309.6604 293.5743,-298.8536\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"295.0273,-302.0577 303.3915,-295.5547 292.7975,-295.4223 295.0273,-302.0577\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709635536 -->\n<g class=\"node\" id=\"node7\">\n<title>139965709635536</title>\n<polygon fill=\"none\" points=\"268,-332.5 268,-378.5 542,-378.5 542,-332.5 268,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-351.8\">epsilon: InputLayer</text>\n<polyline fill=\"none\" points=\"397,-332.5 397,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"397,-355.5 455,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"455,-332.5 455,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-363.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"455,-355.5 542,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-340.3\">(None, 128)</text>\n</g>\n<!-- 139965709635536&#45;&gt;139965709585376 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139965709635536-&gt;139965709585376</title>\n<path d=\"M395.8077,-332.3799C392.4744,-323.9962 388.6425,-314.3584 385.0408,-305.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"388.2045,-303.7834 381.2575,-295.784 381.6998,-306.3696 388.2045,-303.7834\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709585376&#45;&gt;139965606349512 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139965709585376-&gt;139965606349512</title>\n<path d=\"M399.577,-249.3799C410.6407,-240.1043 423.5354,-229.2936 435.2999,-219.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"437.813,-221.8908 443.2275,-212.784 433.3157,-216.5266 437.813,-221.8908\" stroke=\"#000000\"/>\n</g>\n<!-- 139965709585320 -->\n<g class=\"node\" id=\"node11\">\n<title>139965709585320</title>\n<polygon fill=\"none\" points=\"439.5,-83.5 439.5,-129.5 780.5,-129.5 780.5,-83.5 439.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.5\" y=\"-102.8\">z_Y: Concatenate</text>\n<polyline fill=\"none\" points=\"555.5,-83.5 555.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"584.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"555.5,-106.5 613.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"584.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"613.5,-83.5 613.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"697\" y=\"-114.3\">[(None, 128), (None, 10)]</text>\n<polyline fill=\"none\" points=\"613.5,-106.5 780.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"697\" y=\"-91.3\">(None, 138)</text>\n</g>\n<!-- 139965606349512&#45;&gt;139965709585320 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139965606349512-&gt;139965709585320</title>\n<path d=\"M509.7192,-166.3799C525.9999,-156.6583 545.1046,-145.2505 562.2465,-135.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"564.2149,-137.9159 571.0063,-129.784 560.6261,-131.9058 564.2149,-137.9159\" stroke=\"#000000\"/>\n</g>\n<!-- 139965606349288 -->\n<g class=\"node\" id=\"node10\">\n<title>139965606349288</title>\n<polygon fill=\"none\" points=\"632.5,-166.5 632.5,-212.5 867.5,-212.5 867.5,-166.5 632.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"681\" y=\"-185.8\">Y: InputLayer</text>\n<polyline fill=\"none\" points=\"729.5,-166.5 729.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"758.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"729.5,-189.5 787.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"758.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"787.5,-166.5 787.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"827.5\" y=\"-197.3\">(None, 10)</text>\n<polyline fill=\"none\" points=\"787.5,-189.5 867.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"827.5\" y=\"-174.3\">(None, 10)</text>\n</g>\n<!-- 139965606349288&#45;&gt;139965709585320 -->\n<g class=\"edge\" id=\"edge12\">\n<title>139965606349288-&gt;139965709585320</title>\n<path d=\"M711.0022,-166.3799C694.6044,-156.6583 675.3623,-145.2505 658.0971,-135.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"659.6611,-131.8731 649.2742,-129.784 656.0912,-137.8944 659.6611,-131.8731\" stroke=\"#000000\"/>\n</g>\n<!-- 139965606441704 -->\n<g class=\"node\" id=\"node12\">\n<title>139965606441704</title>\n<polygon fill=\"none\" points=\"473,-.5 473,-46.5 747,-46.5 747,-.5 473,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-19.8\">decoder: Sequential</text>\n<polyline fill=\"none\" points=\"602,-.5 602,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"631\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"602,-23.5 660,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"631\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"660,-.5 660,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"703.5\" y=\"-31.3\">(None, 138)</text>\n<polyline fill=\"none\" points=\"660,-23.5 747,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"703.5\" y=\"-8.3\">(None, 794)</text>\n</g>\n<!-- 139965709585320&#45;&gt;139965606441704 -->\n<g class=\"edge\" id=\"edge13\">\n<title>139965709585320-&gt;139965606441704</title>\n<path d=\"M610,-83.3799C610,-75.1745 610,-65.7679 610,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"613.5001,-56.784 610,-46.784 606.5001,-56.784 613.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq6ituXQ8kxm",
        "colab_type": "text"
      },
      "source": [
        "# **Model fitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WTEgt9g8kxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data extraction\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, original_dim-10) / 255. # NORMALIZATION\n",
        "x_test = x_test.reshape(-1, original_dim-10) / 255.\n",
        "#creating one-hot vector for each digit\n",
        "Y_train=np.zeros((60000,10))\n",
        "\n",
        "\n",
        "for i in range(60000):\n",
        "    Y_train[i,y_train[i]]=1\n",
        "\n",
        "Y_test=np.zeros((10000,10))\n",
        "for i in range(10000):\n",
        "    Y_test[i,y_test[i]]=1\n",
        "    \n",
        "#Concatinationg the pixels of the digit with Y the one-hot vector representing the Class of the digit \n",
        "x_train=np.concatenate((Y_train,x_train),axis=1)\n",
        "x_test=np.concatenate((Y_test,x_test),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9teWhEDNRmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3000a09-396d-494c-b7fb-a805bec2e1eb"
      },
      "source": [
        "x_train.shape[:]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 794)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pEj2u-VOG-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77edbb43-a4a3-49e9-a97e-8a57061571e4"
      },
      "source": [
        "Y_train.shape[:]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9K0qrp08kyA",
        "colab_type": "code",
        "outputId": "1400ce6c-090c-4b03-ab08-199561f6b989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training the VAE\n",
        "hist = vae.fit(\n",
        "    x_train,\n",
        "    x_train,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(x_test,x_test)\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 164.6780 - val_loss: 140.1856\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 133.8191 - val_loss: 127.7965\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 123.5853 - val_loss: 118.9121\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 117.0416 - val_loss: 113.6606\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 112.9421 - val_loss: 111.0126\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 110.2710 - val_loss: 108.3041\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 108.4764 - val_loss: 107.4796\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 107.2865 - val_loss: 105.8047\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 106.3964 - val_loss: 105.0252\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 105.7319 - val_loss: 104.9141\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 105.2034 - val_loss: 103.6802\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 104.7430 - val_loss: 104.3372\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 104.3550 - val_loss: 103.4566\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 104.0338 - val_loss: 103.7441\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 103.7752 - val_loss: 102.8307\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 103.5184 - val_loss: 103.3577\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 103.3278 - val_loss: 102.6386\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 103.1280 - val_loss: 103.2038\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 102.9170 - val_loss: 102.3359\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 102.7852 - val_loss: 102.5611\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 102.6226 - val_loss: 102.3554\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 102.5175 - val_loss: 102.1573\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 102.3481 - val_loss: 102.8224\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 102.2685 - val_loss: 102.0797\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 102.1409 - val_loss: 101.4631\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 102.0501 - val_loss: 102.3778\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 101.9780 - val_loss: 102.4174\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.8836 - val_loss: 101.2131\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.8110 - val_loss: 101.4096\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.6847 - val_loss: 101.2585\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.5964 - val_loss: 101.6839\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.5363 - val_loss: 101.3917\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 101.4944 - val_loss: 101.2363\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.4070 - val_loss: 101.1207\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 101.3290 - val_loss: 100.9084\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.2607 - val_loss: 101.0211\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 101.2689 - val_loss: 101.6564\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 101.1800 - val_loss: 100.4928\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 101.1563 - val_loss: 101.1062\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 101.0889 - val_loss: 100.6743\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 101.0000 - val_loss: 100.6042\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 100.9931 - val_loss: 101.0431\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 100.9577 - val_loss: 100.8052\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 100.9280 - val_loss: 100.6707\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 100.8943 - val_loss: 100.4875\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 100.8122 - val_loss: 100.6532\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 100.7953 - val_loss: 100.3240\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 100.7463 - val_loss: 100.9101\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 100.7064 - val_loss: 100.3972\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 100.6862 - val_loss: 100.7080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UBEL23z8kyL",
        "colab_type": "text"
      },
      "source": [
        "# **Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTvaUEa9MzXZ",
        "colab_type": "text"
      },
      "source": [
        "Training a model means minimizing a loss function. However, in variational inference, we maximize the ELBO (which is not a loss function). Hence, this leads to awkwardness where we minimize the the **NEGATIVE** ELBO, as optimizers in nerual networks only support minimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Oyv4DzLvzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAlVRpDE8kyN",
        "colab_type": "code",
        "outputId": "619d451b-ae14-4c1e-83a8-25048c39f415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "golden_size = lambda width: (width, 2. * width / (1 + np.sqrt(5)))\n",
        "#NELBO\n",
        "fig, ax = plt.subplots(figsize=golden_size(6))\n",
        "\n",
        "hist_df = pd.DataFrame(hist.history)\n",
        "hist_df.plot(ax=ax)\n",
        "\n",
        "ax.set_ylabel('NELBO')\n",
        "ax.set_xlabel('# epochs')\n",
        "\n",
        "ax.set_ylim(.99*hist_df[1:].values.min(), \n",
        "            1.1*hist_df[1:].values.max())\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x266.991 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}